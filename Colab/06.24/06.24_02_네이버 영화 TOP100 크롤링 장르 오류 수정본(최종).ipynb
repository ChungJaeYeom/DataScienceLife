{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"06.24_02_네이버 영화 TOP100 크롤링 장르 오류 수정본(최종).ipynb","provenance":[{"file_id":"1wtFahmh3F4nSq0XWV9KK67LKpt3k6kS1","timestamp":1624502764739}],"collapsed_sections":[],"authorship_tag":"ABX9TyPgYLYqMWSES0lnnTFTiawF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"ijvbM--2oF7X"},"source":["링크 수집을 위한 라이브러리 설치"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nGQB1rXtmDPA","executionInfo":{"status":"ok","timestamp":1624500866958,"user_tz":-540,"elapsed":2919,"user":{"displayName":"염충재","photoUrl":"","userId":"04432579223310047056"}},"outputId":"21d49920-fe7d-4cd0-ba8b-a0feb2365c03"},"source":["!pip install selenium"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: selenium in /usr/local/lib/python3.7/dist-packages (3.141.0)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from selenium) (1.24.3)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"q3Ktvmkcn-JG"},"source":["라이브러리 임포트"]},{"cell_type":"code","metadata":{"id":"qkEQ1TUqoesg"},"source":["from bs4 import BeautifulSoup\n","import requests\n","from selenium import webdriver as wd\n","from selenium.webdriver.common.keys import Keys\n","import time\n","import re\n","import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yVvWM7_go4mY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624500876720,"user_tz":-540,"elapsed":9783,"user":{"displayName":"염충재","photoUrl":"","userId":"04432579223310047056"}},"outputId":"92c64c19-8712-418e-a97a-ea72dc2a6a69"},"source":["# install chromium, its driver, and selenium\n","!apt-get update\n","!apt install chromium-chromedriver\n","!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n","!pip install selenium\n","# set options to be headless, ..\n","from selenium import webdriver\n","options = webdriver.ChromeOptions()\n","options.add_argument('--headless')\n","options.add_argument('--no-sandbox')\n","options.add_argument('--disable-dev-shm-usage')\n","\n","driver = webdriver.Chrome('chromedriver',options=options)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\r0% [Working]\r            \rIgn:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com] [Conn\r                                                                               \rIgn:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com] [Conn\r                                                                               \rHit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n","Hit:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Hit:5 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n","Get:6 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","Hit:8 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n","Hit:9 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Hit:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n","Hit:12 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Hit:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n","Hit:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n","Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Fetched 88.7 kB in 2s (40.5 kB/s)\n","Reading package lists... Done\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","chromium-chromedriver is already the newest version (91.0.4472.101-0ubuntu0.18.04.1).\n","0 upgraded, 0 newly installed, 0 to remove and 70 not upgraded.\n","cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n","Requirement already satisfied: selenium in /usr/local/lib/python3.7/dist-packages (3.141.0)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from selenium) (1.24.3)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"j7kCKTpssJYi"},"source":["분석할 데이터 모으기(크롤링) <br>\n","네이버 영화 TOP100 페이지 별 링크 수집"]},{"cell_type":"code","metadata":{"id":"uzzveJDFpF5u"},"source":["#https://serieson.naver.com/movie/top100List.nhn?&rankingTypeCode=PC_R&page=실시간\n","#https://serieson.naver.com/movie/top100List.nhn?&rankingTypeCode=PC_W&page=주간\n","#https://serieson.naver.com/movie/top100List.nhn?&rankingTypeCode=PC_D&page=일간\n","#https://serieson.naver.com/movie/top100List.nhn?&rankingTypeCode=PC_M&page=월간"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GClOjY7Osrxq"},"source":["def getPageLinksWantRange(startPageNo, lastPageNo):\n","  links = [] # 100개의 영화 링크를 수집할 리스트 변수 선언\n","\n","  for pageNo in range(startPageNo -1, lastPageNo):\n","    #실시간 TOP 100 영화 링크 수집\n","    url = \"https://serieson.naver.com/movie/top100List.nhn?rankingTypeCode=PC_R&page=\" +str(pageNo+1)\n","\n","    req = requests.get(url) # 페이지 접속\n","    soup = BeautifulSoup(req.text,'lxml') #html 파싱을 위한 객체 생성\n","    movielinks = soup.select('div.lst_thum_wrap ul li a[href]') # 순서대로 div 안에 있는 li 안에 있는 a 안에 있는\n","                                                                #<div class=\"lst_thum_wrap\"> -> <ul> -> <li> -> <a href =\"\">\n","    for movielink in movielinks:\n","      link = str(movielink.get('href'))\n","      links.append(\"https://series.naver.com\"+link) \n","\n","  return links"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a7ktK49RypNo"},"source":["네이버 영화 제목, 평점, 장르, 줄거리 크롤링"]},{"cell_type":"code","metadata":{"id":"6363KG46ymKG"},"source":["def getMovieDataFromNaverSeries(links):\n","  title_infos = [] # 제목\n","  content_infos = [] # 줄거리\n","  genre_infos = [] # 장르\n","  score_infos = [] # 평점\n","  date_infos = [] # 개봉일\n","\n","  url2 = \"https://www.naver.com\"\n","\n","  driver = webdriver.Chrome('chromedriver',options=options)\n","  driver.get(url2)\n","  time.sleep(3.0) #3초 sleep 사람이 진짜 보는 것처럼 만들기 위해 / 잠깐 쉬는 시간\n","\n","  driver.find_element_by_css_selector('body').send_keys(Keys.CONTROL + \"t\")\n","\n","  for link in links:\n","    print(link + ' 수집 중......')\n","    driver.switch_to_window(driver.window_handles[-1])\n","    time.sleep(0.1)\n","    driver.get(link)\n","    time.sleep(0.1)\n","    #새로운 창 활성화\n","    driver.switch_to_window(driver.window_handles[0])\n","    time.sleep(3.0)\n","\n","    html_source = driver.page_source # req.text 같은 동작\n","    html_soup = BeautifulSoup(html_source, 'lxml')\n","\n","    # 청소년관람불가 영화 크롤링 할 경우 -> 인증 -> 수집 제외\n","    # 청소년관람불가 영화 크롤링 할 경우, 로그인 필요한 부분 check\n","    flag = html_soup.text[0:10]\n","    newflag = \"\".join(flag)\n","    newflag = newflag.replace('\\n', '')\n","\n","    if newflag == '네이버':\n","      time.sleep(1.0)\n","\n","      #평점 수집\n","      score = driver.find_element_by_css_selector('div.score_area > em')\n","      score = float(score.text)\n","      score = int(score)\n","      score_infos.append(score)\n","      \n","\n","      #장르 수집\n","      # try안으로 이동\n","      \n","      #제목, 줄거리\n","      try:\n","        movieInfoUrl = driver.find_element_by_css_selector('li.info_lst > ul > li:nth-child(7) > a').get_attribute('href')\n","        #추가 수정부분\n","        genre = driver.find_element_by_css_selector('li.info_lst > ul > li:nth-child(4)').get_attribute('textContent')\n","        genre = genre.replace('장르' ,'')\n","        genre = genre.replace('\\n','')\n","        genre = genre.replace('\\t','')\n","        genre_infos.append(genre)\n","      \n","      except:\n","        movieInfoUrl = driver.find_element_by_css_selector('li.info_lst > ul > li:nth-child(6) > a').get_attribute('href')\n","        genre_infos.append('') # 추가 수정부분\n","\n","      #영화 상세보기 페이지로 이동\n","      movie_req = requests.get(movieInfoUrl) \n","\n","      #제목 수집\n","      movie_soup = BeautifulSoup(movie_req.text, 'lxml')\n","      title = movie_soup.head.find(\"meta\", {\"property\":\"og:title\"}).get('content')\n","      title_infos.append(title)\n","      #print(title)\n","\n","      #줄거리 수집\n","      contents_texts = movie_soup.select('div.story_area > p.con_tx')\n","\n","      if len(contents_texts) == 0:\n","        content_infos.append(\"줄거리 오류\")\n","\n","      else:\n","        for contents in contents_texts:\n","          #줄거리 데이터 클랜징 작업\n","          temp = contents.text\n","          temp = temp.replace('\\r','') #줄바꿈 제거\n","          temp = temp.replace('\\xa0','') #공백 제거\n","          content_infos.append(temp)\n","\n","    elif newflag == '':\n","        print('청불 영화로 데이터 수집하지 않습니다.')\n","  print('수집 완료 합니다.....')\n","  print(len(score_infos),len(genre_infos),len(content_infos))\n","  driver.close()\n","\n","  movie_dic = {\"제목\":title_infos, \"평점\":score_infos, \"장르\":genre_infos, \"줄거리\":content_infos}\n","  #딕셔너리 -> DataFrame\n","  movie_df = pd.DataFrame(movie_dic)\n","\n","  #수집된 정보 중에 중복 데이터 삭제\n","  movie_df2 = movie_df.drop_duplicates(\"줄거리\",keep='first') #줄거리 비교해서, 중복된 영화를 삭제 (첫 번째 수집 영화만 남김)\n","\n","  return movie_df2\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3uoHi0blLQUc"},"source":["CSV 파일로 저장"]},{"cell_type":"code","metadata":{"id":"tHT9KkKEF2Er"},"source":["def dftoCsv(movie_df,num):\n","  try:\n","    movie_df.to_csv(('movie_my_data_'+str(num)+'csv'),\n","                    sep=',',na_rep='NaN',encoding='euc-kr')\n","  except:\n","    print(\"Error\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wt7zQ7jiLtSh"},"source":["#1. 크롤링 할 링크 생성\n","links = getPageLinksWantRange(1,5)\n","\n","#2. 영화 상세 정보 수집\n","movie_df2 = getMovieDataFromNaverSeries(links)\n","\n","#3. csv 파일 저장\n","dftoCsv(movie_df2,len(movie_df2))"],"execution_count":null,"outputs":[]}]}